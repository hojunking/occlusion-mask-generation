{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "#from sam_segment import predict_masks_with_sam\n",
    "from utils import load_img_to_array, save_array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'data/images/'\n",
    "label_folder = 'data/labels/'\n",
    "mask_output_folder = 'data/masks/'  # 마스크를 저장할 폴더 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    }
   ],
   "source": [
    "file_names = [os.path.splitext(f)[0] for f in os.listdir(image_folder) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "print(len(file_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_coordinate_to_absolute(norm_x, norm_y, file_name):\n",
    "    \n",
    "    image_width, image_height=1280,720\n",
    "    if len(file_name) > 40:\n",
    "        image_width, image_height= 1920, 1200\n",
    "        \n",
    "    abs_x = int(norm_x * image_width)\n",
    "    abs_y = int(norm_y * image_height)\n",
    "    return [abs_x, abs_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_to_xyxy(norm_x_center, norm_y_center, norm_width, norm_height, file_name):\n",
    "    abs_center_x, abs_center_y = normalized_coordinate_to_absolute(norm_x_center, norm_y_center, file_name)\n",
    "    abs_width, abs_height = normalized_coordinate_to_absolute(norm_width, norm_height, file_name)\n",
    "\n",
    "    # Calculate the top-left and bottom-right coordinates\n",
    "    x_min = abs_center_x - abs_width // 2\n",
    "    y_min = abs_center_y - abs_height // 2\n",
    "    x_max = abs_center_x + abs_width // 2\n",
    "    y_max = abs_center_y + abs_height // 2\n",
    "\n",
    "    return [x_min, y_min, x_max, y_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinates(txt_folder_path, img_folder_path):\n",
    "    # 이미지 폴더에서 모든 파일명을 가져옴\n",
    "    file_names = [os.path.splitext(f)[0] for f in os.listdir(img_folder_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    # 데이터를 저장할 리스트 초기화\n",
    "    data = []\n",
    "\n",
    "    for file_name in file_names:\n",
    "        txt_file = os.path.join(txt_folder_path, file_name + '.txt')\n",
    "\n",
    "        # 해당 .txt 파일이 존재하는지 확인\n",
    "        if os.path.exists(txt_file):\n",
    "            with open(txt_file, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                for line in lines:\n",
    "                    try:\n",
    "                        class_id, x_center, y_center, width, height = line.strip().split()\n",
    "                        data.append({\n",
    "                            \"file_id\": file_name,\n",
    "                            \"x_center\": float(x_center),\n",
    "                            \"y_center\": float(y_center),\n",
    "                            \"width\": float(width),\n",
    "                            \"height\": float(height),\n",
    "                            \"label\": int(class_id)\n",
    "                        })\n",
    "                    except ValueError:\n",
    "                        print(f\"Line parsing error in file {file_name}: {line}\")\n",
    "        else:\n",
    "            print(f\"No annotation for image {file_name}\")\n",
    "\n",
    "    # 데이터프레임 생성\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_coordinates(txt_folder_path, img_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>20231031_4b0462d1-da22-483d-92e3-f5769d89c144</td>\n",
       "      <td>0.474242</td>\n",
       "      <td>0.799283</td>\n",
       "      <td>0.089063</td>\n",
       "      <td>0.156667</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>20231031_4b0462d1-da22-483d-92e3-f5769d89c144</td>\n",
       "      <td>0.486758</td>\n",
       "      <td>0.820398</td>\n",
       "      <td>0.151042</td>\n",
       "      <td>0.178333</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>20231031_4b0462d1-da22-483d-92e3-f5769d89c144</td>\n",
       "      <td>0.518173</td>\n",
       "      <td>0.959274</td>\n",
       "      <td>0.125521</td>\n",
       "      <td>0.080833</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>20231031_4b0462d1-da22-483d-92e3-f5769d89c144</td>\n",
       "      <td>0.972164</td>\n",
       "      <td>0.217613</td>\n",
       "      <td>0.055208</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>20231031_4b0462d1-da22-483d-92e3-f5769d89c144</td>\n",
       "      <td>0.047656</td>\n",
       "      <td>0.469692</td>\n",
       "      <td>0.095312</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>2023-04-21_59.mp4#t=140</td>\n",
       "      <td>0.402481</td>\n",
       "      <td>0.870213</td>\n",
       "      <td>0.173673</td>\n",
       "      <td>0.257353</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>2023-04-21_59.mp4#t=140</td>\n",
       "      <td>0.353894</td>\n",
       "      <td>0.722541</td>\n",
       "      <td>0.117850</td>\n",
       "      <td>0.216912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2023-04-21_59.mp4#t=140</td>\n",
       "      <td>0.366644</td>\n",
       "      <td>0.348154</td>\n",
       "      <td>0.136458</td>\n",
       "      <td>0.299020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>2023-04-21_59.mp4#t=140</td>\n",
       "      <td>0.388697</td>\n",
       "      <td>0.590744</td>\n",
       "      <td>0.099242</td>\n",
       "      <td>0.232958</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>2023-04-21_59.mp4#t=140</td>\n",
       "      <td>0.576844</td>\n",
       "      <td>0.769110</td>\n",
       "      <td>0.062026</td>\n",
       "      <td>0.265931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file_id  x_center  y_center  \\\n",
       "1010  20231031_4b0462d1-da22-483d-92e3-f5769d89c144  0.474242  0.799283   \n",
       "1011  20231031_4b0462d1-da22-483d-92e3-f5769d89c144  0.486758  0.820398   \n",
       "1012  20231031_4b0462d1-da22-483d-92e3-f5769d89c144  0.518173  0.959274   \n",
       "1013  20231031_4b0462d1-da22-483d-92e3-f5769d89c144  0.972164  0.217613   \n",
       "1014  20231031_4b0462d1-da22-483d-92e3-f5769d89c144  0.047656  0.469692   \n",
       "1015                        2023-04-21_59.mp4#t=140  0.402481  0.870213   \n",
       "1016                        2023-04-21_59.mp4#t=140  0.353894  0.722541   \n",
       "1017                        2023-04-21_59.mp4#t=140  0.366644  0.348154   \n",
       "1018                        2023-04-21_59.mp4#t=140  0.388697  0.590744   \n",
       "1019                        2023-04-21_59.mp4#t=140  0.576844  0.769110   \n",
       "\n",
       "         width    height  label  \n",
       "1010  0.089063  0.156667     14  \n",
       "1011  0.151042  0.178333     13  \n",
       "1012  0.125521  0.080833     23  \n",
       "1013  0.055208  0.152500     33  \n",
       "1014  0.095312  0.230000     33  \n",
       "1015  0.173673  0.257353     23  \n",
       "1016  0.117850  0.216912      0  \n",
       "1017  0.136458  0.299020      0  \n",
       "1018  0.099242  0.232958      2  \n",
       "1019  0.062026  0.265931      0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = df[1010:1020]\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = '../wim_data/train/images/2023-04-21_48.mp4#t=0.jpg'\n",
    "point_labels = [1]\n",
    "sam_model_type = \"vit_h\"\n",
    "sam_ckpt = './pretrained_models/sam_vit_h_4b8939.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-24_45.mp4#t=280</td>\n",
       "      <td>0.462414</td>\n",
       "      <td>0.574525</td>\n",
       "      <td>0.167586</td>\n",
       "      <td>0.25</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_id  x_center  y_center     width  height  label\n",
       "0  2023-04-24_45.mp4#t=280  0.462414  0.574525  0.167586    0.25     23"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.iloc[[0]].copy()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-24_45.mp4#t=280</td>\n",
       "      <td>0.462414</td>\n",
       "      <td>0.574525</td>\n",
       "      <td>0.167586</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-24_45.mp4#t=280</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.470358</td>\n",
       "      <td>0.124138</td>\n",
       "      <td>0.127451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-24_45.mp4#t=280</td>\n",
       "      <td>0.625862</td>\n",
       "      <td>0.374157</td>\n",
       "      <td>0.084828</td>\n",
       "      <td>0.121324</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-24_45.mp4#t=280</td>\n",
       "      <td>0.646897</td>\n",
       "      <td>0.282246</td>\n",
       "      <td>0.053793</td>\n",
       "      <td>0.111520</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-24_45.mp4#t=280</td>\n",
       "      <td>0.518276</td>\n",
       "      <td>0.311045</td>\n",
       "      <td>0.080690</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17231</th>\n",
       "      <td>2023-04-24_64.mp4#t=140</td>\n",
       "      <td>0.637330</td>\n",
       "      <td>0.193738</td>\n",
       "      <td>0.101226</td>\n",
       "      <td>0.210913</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17232</th>\n",
       "      <td>2023-04-24_64.mp4#t=140</td>\n",
       "      <td>0.604080</td>\n",
       "      <td>0.061949</td>\n",
       "      <td>0.155527</td>\n",
       "      <td>0.117286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17233</th>\n",
       "      <td>2023-04-24_64.mp4#t=140</td>\n",
       "      <td>0.465657</td>\n",
       "      <td>0.217663</td>\n",
       "      <td>0.124204</td>\n",
       "      <td>0.243011</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17234</th>\n",
       "      <td>2023-04-24_64.mp4#t=140</td>\n",
       "      <td>0.358363</td>\n",
       "      <td>0.383565</td>\n",
       "      <td>0.097756</td>\n",
       "      <td>0.130002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17235</th>\n",
       "      <td>2023-04-24_64.mp4#t=140</td>\n",
       "      <td>0.313362</td>\n",
       "      <td>0.256419</td>\n",
       "      <td>0.056401</td>\n",
       "      <td>0.218901</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17236 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file_id  x_center  y_center     width    height  label\n",
       "0      2023-04-24_45.mp4#t=280  0.462414  0.574525  0.167586  0.250000     23\n",
       "1      2023-04-24_45.mp4#t=280  0.620000  0.470358  0.124138  0.127451      1\n",
       "2      2023-04-24_45.mp4#t=280  0.625862  0.374157  0.084828  0.121324     23\n",
       "3      2023-04-24_45.mp4#t=280  0.646897  0.282246  0.053793  0.111520     25\n",
       "4      2023-04-24_45.mp4#t=280  0.518276  0.311045  0.080690  0.147059     12\n",
       "...                        ...       ...       ...       ...       ...    ...\n",
       "17231  2023-04-24_64.mp4#t=140  0.637330  0.193738  0.101226  0.210913      8\n",
       "17232  2023-04-24_64.mp4#t=140  0.604080  0.061949  0.155527  0.117286      0\n",
       "17233  2023-04-24_64.mp4#t=140  0.465657  0.217663  0.124204  0.243011     13\n",
       "17234  2023-04-24_64.mp4#t=140  0.358363  0.383565  0.097756  0.130002      3\n",
       "17235  2023-04-24_64.mp4#t=140  0.313362  0.256419  0.056401  0.218901      2\n",
       "\n",
       "[17236 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_bd_path = '../wim_data/objects/images_bounding1/'\n",
    "ob_path = '../wim_data/objects/images_object1/'\n",
    "mask_object = '../wim_data/objects/masks_object1/'\n",
    "mask_full_path = '../wim_data/objects/masks_full1/'\n",
    "\n",
    "if not os.path.exists(ob_bd_path):\n",
    "    os.makedirs(ob_bd_path)\n",
    "if not os.path.exists(ob_path):\n",
    "    os.makedirs(ob_path)\n",
    "if not os.path.exists(mask_object):\n",
    "    os.makedirs(mask_object)\n",
    "if not os.path.exists(mask_full_path):\n",
    "    os.makedirs(mask_full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#point_labels = [1]\n",
    "sam_model_type = \"vit_h\"\n",
    "sam_ckpt = './pretrained_models/sam_vit_h_4b8939.pth'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_and_labels_per_image  = defaultdict(list)\n",
    "#latest_coords = normalized_coordinate_to_absolute(x_center, y_center, row.file_id)\n",
    "\n",
    "\n",
    "for index, row in tp.iterrows():\n",
    "    x_center, y_center = row.x_center, row.y_center\n",
    "    norm_width, norm_height = row.width, row.height\n",
    "    \n",
    "    input_box = yolo_to_xyxy(x_center, y_center, norm_width, norm_height, row.file_id)\n",
    "    boxes_and_labels_per_image[row.file_id].append((input_box, row.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20231031_4b0462d1-da22-483d-92e3-f5769d89c144\n",
      "[825, 865, 995, 1053]\n",
      "14\n",
      "[789, 877, 1079, 1091]\n",
      "13\n",
      "[874, 1103, 1114, 1199]\n",
      "23\n",
      "[1813, 170, 1919, 352]\n",
      "33\n",
      "[0, 425, 182, 701]\n",
      "33\n",
      "2023-04-21_59.mp4#t=140\n",
      "[404, 534, 626, 718]\n",
      "23\n",
      "[377, 442, 527, 598]\n",
      "0\n",
      "[382, 143, 556, 357]\n",
      "0\n",
      "[434, 342, 560, 508]\n",
      "2\n",
      "[699, 458, 777, 648]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for file_id, boxes_and_labels  in boxes_and_labels_per_image.items():\n",
    "    print(file_id)\n",
    "    for box, label in boxes_and_labels:\n",
    "        print(box)\n",
    "        print(label)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start SAM\n",
      "Ends SAM\n",
      "scores: tensor([0.9680, 0.9983, 0.9984], device='cuda:0')\n",
      "scores: tensor([0.9218, 0.9281, 0.9206], device='cuda:0')\n",
      "scores: tensor([0.8777, 0.8774, 0.9091], device='cuda:0')\n",
      "scores: tensor([0.9843, 0.9928, 0.9874], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sam = sam_model_registry[sam_model_type](checkpoint=sam_ckpt).to(device=device)\n",
    "mask_predictor = SamPredictor(sam)\n",
    "\n",
    "print('process start')\n",
    "# Process each image\n",
    "for file_id, boxes_and_labels in boxes_and_labels_per_image.items():\n",
    "    labels = []\n",
    "    input_boxs =[]\n",
    "    \n",
    "    input_img_path = img_folder_path + file_id + '.jpg'\n",
    "    img = load_img_to_array(input_img_path)  # Load the image\n",
    "    print('1')\n",
    "    for box, label in boxes_and_labels:\n",
    "        labels.append(label)\n",
    "        input_boxs.append(box)\n",
    "    input_box_tensor = torch.tensor(input_boxs, device=device)\n",
    "    #input_box = yolo_to_xyxy(x_center, y_center, norm_width, norm_height)\n",
    "    print('2')\n",
    "    mask_predictor.set_image(img)\n",
    "    print('transforming...')\n",
    "    transformed_boxes = mask_predictor.transform.apply_boxes_torch(input_box_tensor, img.shape[:2])\n",
    "    \n",
    "    print(\"Start SAM\")\n",
    "    masks, scores, _ = mask_predictor.predict_torch(\n",
    "    boxes = transformed_boxes,\n",
    "    multimask_output=True,\n",
    "    point_coords=None,\n",
    "    point_labels=None\n",
    "    )\n",
    "    print(\"Ends SAM\")\n",
    "    for i in range(masks.shape[0]): ## object 개수\n",
    "        object_masks = masks[i]  # Masks for the current object\n",
    "        object_scores = scores[i]  # Scores for the current object\n",
    "        # Find the mask index with the highest score\n",
    "        print(f'scores: {scores[i]}')\n",
    "        best_mask_index = torch.argmax(object_scores).item()\n",
    "\n",
    "        # Extract the best mask\n",
    "        best_mask = object_masks[best_mask_index].cpu().numpy().astype(np.uint8) * 255\n",
    "\n",
    "        # masks = masks.astype(np.uint8)* 255\n",
    "        # mask_full = masks[2]\n",
    "    \n",
    "        extracted_object = cv2.bitwise_and(img, img, mask=best_mask)\n",
    "        mask_full_cropped = cv2.bitwise_and(best_mask, best_mask)\n",
    "        \n",
    "        x, y, w, h = cv2.boundingRect(best_mask)\n",
    "        cropped_image = extracted_object[y:y+h, x:x+w]\n",
    "        cropped_mask = mask_full_cropped[y:y+h, x:x+w]\n",
    "        \n",
    "        common_name = f\"{file_id}_{labels[i]}_{i:02}.png\"\n",
    "        \n",
    "        cropped_object = cv2.bitwise_and(cropped_image, cropped_image, mask=cropped_mask)\n",
    "        \n",
    "        cropped_bd_object = cv2.cvtColor(extracted_object[y:y+h, x:x+w], cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 배경을 투명하게 만들기 위해 알파 채널 추가\n",
    "        b_channel, g_channel, r_channel = cv2.split(cropped_object)\n",
    "        alpha_channel = np.where(cropped_mask==255, 255, 0).astype(np.uint8)  # 마스크에 따라 알파 채널 설정\n",
    "        rgba_image = cv2.merge((b_channel, g_channel, r_channel, alpha_channel))\n",
    "        \n",
    "        save_array_to_img(cropped_mask, mask_object+common_name)\n",
    "        save_array_to_img(best_mask, mask_full_path+common_name)\n",
    "        save_array_to_img(rgba_image, ob_path+common_name)\n",
    "        save_array_to_img(cropped_bd_object, ob_bd_path+common_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " x_center, y_center = row.x_center, row.y_center\n",
    "    norm_width, norm_height = row.width, row.height\n",
    "     \n",
    "    \n",
    "    input_box = yolo_to_xyxy(x_center, y_center, norm_width, norm_height)\n",
    "    \n",
    "    #latest_coords = normalized_coordinate_to_absolute(x_center, y_center, row.file_id)\n",
    "    sam = sam_model_registry[sam_model_type](checkpoint=sam_ckpt).to(device=device)\n",
    "    mask_predictor = SamPredictor(sam)\n",
    "    mask_predictor.set_image(img)\n",
    "    \n",
    "    transformed_boxes = mask_predictor.transform.apply_boxes_torch(.boxes.xyx, img.shape[:2])\n",
    "    \n",
    "    masks = masks.astype(np.uint8)* 255\n",
    "    mask_full = masks[2]\n",
    "    \n",
    "    extracted_object = cv2.bitwise_and(img, img, mask=mask_full)\n",
    "    mask_full_cropped = cv2.bitwise_and(mask_full, mask_full)\n",
    "    \n",
    "    x, y, w, h = cv2.boundingRect(mask_full)\n",
    "    cropped_image = extracted_object[y:y+h, x:x+w]\n",
    "    cropped_mask = mask_full_cropped[y:y+h, x:x+w]\n",
    "    \n",
    "    common_name = f\"{row.file_id}_{row.label}_{row.x_center}_{row.y_center}.png\"\n",
    "    \n",
    "    cropped_object = cv2.bitwise_and(cropped_image, cropped_image, mask=cropped_mask)\n",
    "    \n",
    "    cropped_bd_object = cv2.cvtColor(extracted_object[y:y+h, x:x+w], cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 배경을 투명하게 만들기 위해 알파 채널 추가\n",
    "    b_channel, g_channel, r_channel = cv2.split(cropped_object)\n",
    "    alpha_channel = np.where(cropped_mask==255, 255, 0).astype(np.uint8)  # 마스크에 따라 알파 채널 설정\n",
    "    rgba_image = cv2.merge((b_channel, g_channel, r_channel, alpha_channel))\n",
    "    \n",
    "    save_array_to_img(cropped_mask, mask_object+common_name)\n",
    "    save_array_to_img(mask_full, mask_full_path+common_name)\n",
    "    save_array_to_img(rgba_image, ob_path+common_name)\n",
    "    save_array_to_img(cropped_bd_object, ob_bd_path+common_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_bgr = cv2.imread(\"{}/{}\".format(HOME, os.path.basename(IMAGE_PATH)), cv2.IMREAD_COLOR)\n",
    "\n",
    "transformed_boxes = mask_predictor.transform.apply_boxes_torch(results[0].boxes.xyxy, image_bgr.shape[:2])\n",
    "\n",
    "mask_predictor.set_image(image_bgr)\n",
    "\n",
    "masks, scores, logits = mask_predictor.predict_torch(\n",
    "    boxes = transformed_boxes,\n",
    "    multimask_output=False,\n",
    "    point_coords=None,\n",
    "    point_labels=None\n",
    ")\n",
    "masks = np.array(masks.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "masks, _, _ = predict_masks_with_sam(\n",
    "        img,\n",
    "        [latest_coords],\n",
    "        point_labels,\n",
    "        model_type=sam_model_type,\n",
    "        ckpt_p=sam_ckpt,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
